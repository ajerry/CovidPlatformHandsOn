{"cells":[{"cell_type":"markdown","source":["#Notebook shortcuts\n\n### shift+enter = Run cell and move to the next one\n\n### ctrl+alt+P = insert cell above\n### ctrl+alt+N = insert cell below\n\n### ctrl+alt+up = move cell up\n### ctrl+alt+down = move cell down\n\n\nfor more shortcuts go to https://docs.microsoft.com/en-us/azure/databricks/notebooks/notebooks-use"],"metadata":{}},{"cell_type":"markdown","source":["# Start here if the Lake has been mounted to this cluster"],"metadata":{}},{"cell_type":"markdown","source":["Check file structure is setup"],"metadata":{}},{"cell_type":"code","source":["display(dbutils.fs.ls(\"/mnt/coviddata/\"))\n        "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/mnt/coviddata/inputs/</td><td>inputs/</td><td>0</td></tr><tr><td>dbfs:/mnt/coviddata/outputs/</td><td>outputs/</td><td>0</td></tr></tbody></table></div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["Check all the required files are visible"],"metadata":{}},{"cell_type":"code","source":["display(dbutils.fs.ls(\"/mnt/coviddata/inputs/\"))"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["#Wrangle the Doctor Data"],"metadata":{}},{"cell_type":"code","source":["filepath2=\"/mnt/coviddata/inputs/DoctorCountLatest.csv\"\n"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["###Infer the schema and load the data to a spark data frame. \n### Cache the data for faster operations"],"metadata":{}},{"cell_type":"code","source":["doctorraw = spark.read.format('csv').options(header='false', inferSchema='true').load(filepath2)\ndoctorraw.cache()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["### Check if schema was inferred correctly"],"metadata":{}},{"cell_type":"code","source":["doctorraw.printSchema()"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["### Display the data in a nice readable format"],"metadata":{}},{"cell_type":"code","source":["display(doctorraw)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["### focus on the columns we want to work with"],"metadata":{}},{"cell_type":"code","source":["display(doctorraw.select(\"_c3\",\"_c5\",\"_c15\"))"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["doctorraw.select(\"_c3\",\"_c5\",\"_c15\").show()"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":["### filter the data so that there is only the doctor per 10k count for the most recent year for each country in the list. We only need the latest year."],"metadata":{}},{"cell_type":"code","source":["doctorlatest=doctorraw.groupBy(\"_c3\").max(\"_c5\",\"_c15\")"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["### just confirm that Australia exists in the data set we're pulling"],"metadata":{}},{"cell_type":"code","source":["doctorlatest.filter(\"_c3= 'AUS'\").show()"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["display(doctorlatest)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["### rename the columns"],"metadata":{}},{"cell_type":"code","source":["doctorlatest=doctorlatest.withColumnRenamed(\"_c3\",'COUNTRY').withColumnRenamed(\"max(_c5)\",'YEAR').withColumnRenamed(\"max(_c15)\",'DoctorsPer10k')"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["doctorlatest.printSchema()"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["doctorlatest.printSchema()"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":["### save it to csv on our data lake"],"metadata":{}},{"cell_type":"code","source":["doctorlatest.write.mode('overwrite').option(\"header\",\"true\").csv('/mnt/coviddata/outputs/DoctorCountLatestYear')"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":["###Load the country code data"],"metadata":{}},{"cell_type":"code","source":["filepath3=\"/mnt/coviddata/inputs/UID_ISO_FIPS_LookUp_Table.csv\""],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["countrycodes = spark.read.format('csv').options(header='true', inferSchema='true').load(filepath3)"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["countrycodes.printSchema()"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["countrycodes.show()"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":["### just want country region and iso3"],"metadata":{}},{"cell_type":"code","source":["countrycodeiso3=countrycodes.select(\"iso3\",\"Country_Region\").distinct()"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["countrycodeiso3.filter(\"iso3='AUS'\").show()"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["countrycodeiso3.write.mode('overwrite').csv('/mnt/coviddata/outputs/CountryCodesISO3')"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":["#Wrangle the COVID Data\n\n### load the covid data and summarize by country\n### join the summarized data with the count of doctors and country codes"],"metadata":{}},{"cell_type":"code","source":["# Creating widgets for leveraging parameters, and printing the parameters\n\ndbutils.widgets.text(\"input\", \"\",\"\")\ny = dbutils.widgets.get(\"input\")\nprint (\"Param -\\'input':\")\nprint (y)\n\ndbutils.widgets.text(\"fileDate\", \"\",\"\")\nz = dbutils.widgets.get(\"fileDate\")\nprint (\"Param -\\'fileDate':\")\nprint (z)\n\ndbutils.widgets.text(\"name\", \"\",\"\")\nu = dbutils.widgets.get(\"name\")\nprint (\"Param -\\'name':\")\nprint (u)\n\ndbutils.widgets.text(\"name2\", \"\",\"\")\nv = dbutils.widgets.get(\"name2\")\nprint (\"Param -\\'name2':\")\nprint (v)"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["filepath = \"/mnt/coviddata/inputs/latestcovidcount.csv\""],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":["### infer the schema and load the data into a spark dataframe"],"metadata":{}},{"cell_type":"code","source":["covidraw = spark.read.format('csv').options(header='true', inferSchema='true').load(filepath)\n"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":["display(covidraw)"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"code","source":["covidlatest=covidraw.select(\"Country_Region\",\"Confirmed\",\"Deaths\",\"Recovered\").groupby(\"Country_Region\").sum(\"Confirmed\",\"Deaths\",\"Recovered\")"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"code","source":["display(covidlatest)"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":["#covidlatest.write.mode('overwrite').csv('/mnt/coviddata/outputs/CovidLatest')"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":["doctorlatest.show()"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"code","source":["countrycodeiso3.show()"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"code","source":["from pyspark.sql.functions import col\ndoctoriso3=doctorlatest.join(countrycodeiso3,col(\"COUNTRY\")==col(\"iso3\"))"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"code","source":["doctoriso3.select(\"COUNTRY\",\"YEAR\",\"DoctorsPer10k\",\"Country_Region\").filter(\"COUNTRY = 'AUS'\").show()"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"code","source":["coviddoctors = covidlatest.join(doctoriso3, doctoriso3.Country_Region == covidlatest.Country_Region)"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"code","source":["coviddoctors.show()"],"metadata":{},"outputs":[],"execution_count":52},{"cell_type":"code","source":["coviddoctorselect = coviddoctors.select(covidlatest.Country_Region,\"sum(Confirmed)\",\"sum(Deaths)\",\"sum(Recovered)\",\"COUNTRY\",\"YEAR\",\"DoctorsPer10k\")"],"metadata":{},"outputs":[],"execution_count":53},{"cell_type":"code","source":["coviddoctorfinal=coviddoctorselect\\\n.withColumnRenamed('sum(Confirmed)','Confirmed')\\\n.withColumnRenamed('sum(Deaths)','Deaths')\\\n.withColumnRenamed('sum(Recovered)','Recovered')\\\n.withColumnRenamed('COUNTRY','Iso3')\\\n.withColumnRenamed('YEAR','YearOfDoctorCount')"],"metadata":{},"outputs":[],"execution_count":54},{"cell_type":"code","source":["coviddoctorfinal.printSchema()"],"metadata":{},"outputs":[],"execution_count":55},{"cell_type":"code","source":["coviddoctorfinal.write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"/mnt/coviddata/outputs/CovidDoctorCombined\")"],"metadata":{},"outputs":[],"execution_count":56},{"cell_type":"code","source":["#dbutils.fs.mkdirs(\"/mnt/coviddata/outputs/final\")"],"metadata":{},"outputs":[],"execution_count":57},{"cell_type":"markdown","source":["### for the data factory to correctly copy these shards to Synapse, we need to remove any unneeded files from the output directory. Since trying to find files that begin with \"_\" seem to throw java, we will look for all the .csv files and move them to a clean directory and then point the factory to that as the source"],"metadata":{}},{"cell_type":"code","source":["%scala\n\nval fileprefix= \"/mnt/coviddata/outputs/final/\"\nval partition_path = dbutils.fs.ls(\"/mnt/coviddata/outputs/CovidDoctorCombined\")\n     .filter(file=>file.name.endsWith(\"csv\"))//(0).path\n\npartition_path.foreach { file => dbutils.fs.cp(file.path,fileprefix+file.name)}\n\n//partition_path.show()\n\n//partition_path.toDF().foreach { file => dbutils.fs.cp(file(0).toString,)}//.toString, true)}\n\n\n//dbutils.fs.cp(partition_path,fileprefix+\".tab\")\n\n//dbutils.fs.rm(fileprefix+\".tmp\",recurse=true)"],"metadata":{},"outputs":[],"execution_count":59},{"cell_type":"code","source":["display(dbutils.fs.ls('/mnt/coviddata/outputs/final/'))"],"metadata":{},"outputs":[],"execution_count":60}],"metadata":{"name":"Covid19HackPipeDbNb","notebookId":2230262694659239},"nbformat":4,"nbformat_minor":0}
